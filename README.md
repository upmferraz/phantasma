# Phantasma Voice Assistant

Phantasma √© um assistente de voz local-first (offline) e modular, constru√≠do em Python. Ele foi desenhado para ser privado, correndo inteiramente no teu pr√≥prio servidor, sem depender de servi√ßos de nuvem de terceiros (exceto para pesquisas na web, que s√£o feitas atrav√©s da tua pr√≥pria inst√¢ncia do SearxNG).

Ele usa `openwakeword` para a dete√ß√£o da *hotword*, `whisper` para transcri√ß√£o, `ollama` (Llama3) como c√©rebro, e `piper`/`sox` para uma voz rob√≥tica personalizada.

## Funcionalidades

* **Hotword 100% Offline:** Usa o `openwakeword` para uma dete√ß√£o de *hotword*. Foi aplicada uma fun√ß√£o de VAD para verificar primeiro por atividade de voz para evitar ativa√ß√µes noturnas ou acidentais baseada em webrtcvad.
* **Transcri√ß√£o Local:** Utiliza o `whisper` (modelo `medium`) para transcri√ß√£o de voz para texto.
* **C√©rebro Local (LLM):** Integrado com o `ollama` para usar o modelo `llama3:8b-instruct-8k`.
* **Voz Rob√≥tica (TTS):** Usa o `piper` com efeitos do `sox` para criar a voz do assistente.
* **API e CLI:** Al√©m da voz, pode ser controlado por uma API REST (Flask) e um *script* de CLI (`phantasma-cli.sh`).
* **Sistema de Skills Modular:** As funcionalidades (C√°lculo, Meteorologia, M√∫sica, Mem√≥ria) s√£o carregadas dinamicamente a partir da pasta `skills/`.
* **RAG (Retrieval-Augmented Generation):**
    * **Mem√≥ria de Longo Prazo:** Pode memorizar factos ("phantasma, memoriza isto...") numa base de dados SQLite.
    * **Pesquisa Web:** Enriquece as respostas do Ollama com resultados de pesquisa em tempo real, usando a tua inst√¢ncia local do **SearxNG**.
* **Feedback de √Åudio:** Toca um *snippet* de m√∫sica aleat√≥rio e uma sauda√ß√£o quando a *hotword* √© detetada, para que saibas quando come√ßar a falar.
* **Personalidade:** O *prompt* do sistema est√° configurado para a personalidade do phantasma, com regras para evitar *bugs* de TTS ("WOOHOO") e manter as prefer√™ncias do utilizador (vegan).

---

## Arquitetura e Componentes

| Componente | Tecnologia Utilizada | Prop√≥sito |
| :--- | :--- | :--- |
| **Hotword** | `openwakeword` | Dete√ß√£o offline. |
| **STT (Voz->Texto)** | `openai-whisper` (Medium) | Transcri√ß√£o local. |
| **LLM (C√©rebro)** | `ollama` (Llama3 8K) | Processamento de linguagem. |
| **TTS (Texto->Voz)** | `piper` + `sox` | Gera√ß√£o de voz. |
| **Leitor de M√∫sica** | `mpg123` | Tocar *snippets* e m√∫sicas. |
| **Pesquisa Web** | `searxng` (Docker) | RAG - Contexto da Web. |
| **Mem√≥ria** | `sqlite3` | RAG - Mem√≥ria de Longo Prazo. |
| **API** | `flask` | Receber comandos via `curl`. |
| **Servi√ßo** | `systemd` | Correr o assistente em *background*. |

---

## Instala√ß√£o

### 1. Pr√©-requisitos (Sistema)

Assume-se um servidor Ubuntu/Debian. Estes pacotes s√£o necess√°rios.
sudo apt update
sudo apt install sox mpg123 portaudio19-dev

### 2. Servi√ßos Externos (Ollama e SearxNG)

Este guia assume que j√° tens:
* **Ollama** instalado e a correr.
* **SearxNG** a correr num contentor Docker, acess√≠vel em `http://127.0.0.1:8081`.

### 3. Criar o Modelo 8K do Ollama

Precisas de dizer ao Ollama para usar os 8K de contexto do Llama3.

Cria um ficheiro chamado `Modelfile_Llama3_8k`:
vim Modelfile_Llama3_8k
Cola o seguinte:
FROM llama3:8b-instruct-q5_k_m
PARAMETER num_ctx 8192

Agora, cria o modelo no Ollama:
ollama create llama3:8b-instruct-8k -f Modelfile_Llama3_8k

### 4. Ambiente Python (Venv)


#### Vai para a pasta do projeto
cd /opt/phantasma

#### Apaga o venv antigo (o 3.12)
rm -rf venv

#### O 'pyenv' vai garantir que 'python3' aponta para o 3.11.9
python3 -m venv venv

#### Ativa o venv novo e correto (3.11.9)
source venv/bin/activate

#### Verifica (Opcional):
#### which python3
#### Deve apontar para /opt/phantasma/venv/bin/python3

#### Instala tudo no venv 3.11.9
pip install --upgrade pip
pip install sounddevice openai-whisper ollama torch httpx flask openwakeword dio-chacon-wifi-api tinytuya psutil python-miio webrtcvad

## Configura√ß√£o

### 1. `config.py`

Este √© o ficheiro de controlo principal. Edita-o (`vim config.py`) para ajustar os teus caminhos e chaves:

* `ACCESS_KEY`: A tua chave do Picovoice (Porcupine).
* `SEARXNG_URL`: Garante que est√° a apontar para a tua inst√¢ncia (ex: `http://127.0.0.1:8081`).
* `ALSA_DEVICE_IN` e `ALSA_DEVICE_OUT`: Ajusta os IDs do teu microfone e altifalantes.
    * Usa `arecord -l` para encontrar dispositivos de entrada (Input).
    * Usa `aplay -l` para encontrar dispositivos de sa√≠da (Output).

### 2. `phantasma.service` (systemd)

Cria o ficheiro de servi√ßo para o assistente correr em *background*.

vim /etc/systemd/system/phantasma.service
Cola o seguinte conte√∫do (j√° inclui as corre√ß√µes de `PATH` e prioridade `Nice`):

[Unit]
Description=pHantasma Voice Assistant
After=network-online.target sound.target

[Service]
Type=simple
User=user
Group=group
WorkingDirectory=/opt/phantasma

# Define o HOME e o PATH (para pyenv, piper, sox, mpg123)
Environment="HOME=/opt/phantasma"
Environment="PATH=/opt/phantasma/.pyenv/shims:/usr/local/bin:/usr/bin:/sbin:/bin"

# Define a prioridade do CPU e Disco como a mais baixa
Nice=19
IOSchedulingClass=idle

# Executa o python de dentro da venv
ExecStart=/opt/phantasma/venv/bin/python -u /opt/phantasma/assistant.py

Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target

---

## Execu√ß√£o

Ap√≥s criares todos os ficheiros (`.py`, `config.py`, `.service`):

**1. Recarrega o systemd:**
systemctl daemon-reload

**2. Ativa e Inicia o Servi√ßo:**
systemctl enable --now phantasma.service

**3. V√™ os Logs (para debug):**
journalctl -u phantasma -f

---

## Utiliza√ß√£o

### 1. Comandos de Voz

1.  Diz a *hotword*: **"Fantasma"**.
2.  Espera pela reposta).
3.  Faz o teu pedido (ex: "como vai estar o tempo amanh√£?", "memoriza que o meu gato se chama Bimby", "p√µe m√∫sica").

### 2. Comandos via CLI (`phantasma-cli.sh`)

Usa o *script* `phantasma-cli.sh` para enviar comandos pela API:

**Ajuda (Din√¢mica):**
./phantasma-cli.sh -h

**Comando "diz":**
./phantasma-cli.sh diz ol√°, isto √© um teste

**Comando para o Ollama (com RAG):**
./phantasma-cli.sh quem √© o primeiro-ministro de portugal

**Comando para Skills (Ex: Tocar M√∫sica):**
./phantasma-cli.sh p√µe uma m√∫sica

### 3. Adicionar Novas Skills

Para adicionar uma nova funcionalidade (ex: "abrir o port√£o"):

1.  Cria um novo ficheiro em `/opt/phantasma/skills/` (ex: `skill_portao.py`).
2.  Define os `TRIGGERS` (ex: `["abre o port√£o", "abrir port√£o"]`) e o `TRIGGER_TYPE` ("startswith" ou "contains").
3.  Cria a fun√ß√£o `handle(user_prompt_lower, user_prompt_full)` que executa a l√≥gica.
4.  Reinicia o servi√ßo (`systemctl restart phantasma`). O assistente ir√° carregar a nova *skill* automaticamente.

## ‚öôÔ∏è Integra√ß√£o de Dispositivos Dom√©sticos (Skills de IoT)

O Phantasma utiliza *skills* dedicadas (`skill_xiaomi.py`, `skill_tuya.py`) para o controlo **100% local** dos dispositivos, cumprindo a filosofia **offline-first** do projeto.

### ‚ùó CR√çTICO: Reserva de DHCP

Para que o controlo local funcione de forma fi√°vel, √© **obrigat√≥rio** definir uma **Reserva de DHCP (IP Est√°tico)** no seu router para o **MAC Address** de cada dispositivo. Se o IP mudar, a *skill* falhar√°.

---

## 1. Skill Tuya (SmartLife)

Esta *skill* permite o controlo local de dispositivos Tuya/SmartLife (tomadas, exaustores, luzes).

### A. Depend√™ncias

√â necess√°rio instalar a biblioteca Python para controlo local. Use o terminal (ou abra o ficheiro com o seu editor de elei√ß√£o, como **Vim**, para inspecionar):

pip install tinytuya

### B. Obter Chaves (Device ID e Local Key)

O controlo local Tuya exige o **Device ID (`id`)** e a **Local Key (`key`)** de cada dispositivo. O m√©todo mais fi√°vel √© atrav√©s da **Plataforma de Desenvolvimento Tuya IoT** e da ferramenta `tuya-cli wizard`.

1.  Crie um projeto em [https://iot.tuya.com/](https://iot.tuya.com/) e ligue-o √† sua app SmartLife (via scan de QR Code).
2.  Execute a ferramenta de linha de comandos `tuya-cli wizard` e forne√ßa as chaves de API e Segredo do seu projeto para extrair a **Local Key** de 16 ou 32 caracteres.

### C. Estrutura do `config.py`

Defina os seus dispositivos no dicion√°rio `TUYA_DEVICES` em `config.py`. O Phantasma usa o nome do dispositivo para determinar o c√≥digo **DPS** (Data Point Switch).

| Dispositivo | DPS ON/OFF | Protocolo Status | Observa√ß√£o |
| :--- | :---: | :---: | :--- |
| Exaustor, Tomada, Desumidificador | 1 | 3.3 | DPS 1 √© o padr√£o para switches. |
| L√¢mpada (Luz) | 20 | 3.3 | DPS 20 √© o padr√£o para dispositivos de ilumina√ß√£o mais avan√ßados (Cor, Brilho, etc.). |
| Sensor de T/H | N/A | 3.1 | Leitura de status usa o protocolo mais antigo. |

**Exemplo Completo do `config.py`:**

# config.py

TUYA_DEVICES = {
    # Exaustores e Tomadas (DPS 1)
    "exaustor 1": {
        "ip": "10.0.0.107",       
        "id": "ID_DO_EXAUSTOR_1_32_CHARS",
        "key": "CHAVE_LOCAL_16_CHARS" 
    },
    
    # L√¢mpadas (DPS 20)
    "luz da sala": {
        "ip": "10.0.0.118",       
        "id": "ID_DA_LUZ_32_CHARS",
        "key": "CHAVE_LOCAL_16_CHARS"
    },
    
    # Sensores de Temperatura/Humidade (Leitura de status v3.1)
    "sensor do quarto": {
        "ip": "10.0.0.123",
        "id": "ID_DO_SENSOR_32_CHARS",
        "key": "CHAVE_LOCAL_16_CHARS"
    }
}
### Tuya Daemon
Este daemon serve para recolher dados do estado dos dispositivos tuya, s√£o dados que s√£o enviados por UDP, e recolhidos neste daemon que poder√° e dever√° ser lan√ßado como um servi√ßo. Este Daemon ser√° essencial para recolher os dados de dispositivos como os sensores de temperatura e humidade.

## 2. Skill Xiaomi (Miio)

Esta *skill* integra dispositivos Mi Home (aspiradores, Yeelight, etc.) atrav√©s do protocolo **Miio**.

### A. Depend√™ncias

Instale a biblioteca de c√≥digo aberto `python-miio` para a integra√ß√£o:

pip install python-miio
### B. Obter Token

O controlo Miio exige o **Token** (o equivalente √† Local Key da Tuya).

O **Token (32 caracteres)** √© obtido usando a ferramenta `micloud` ou scripts de extra√ß√£o de terceiros, autenticando-se na nuvem da Xiaomi. Lembre-se de especificar o servidor correto (`de`, `us`, `cn`, etc.) durante a extra√ß√£o.

### C. Estrutura do `config.py`

Defina os seus dispositivos no dicion√°rio `MIIO_DEVICES` em `config.py`.

**Exemplo Completo do `config.py`:**

# config.py

MIIO_DEVICES = {
    # Exemplo: Aspirador Robot (usa a classe ViomiVacuum)
    "robot da sala": {
        "ip": "10.0.0.X",
        "token": "SEU_TOKEN_32_CHARS_ASPIRADOR" # <-- Token de 32 caracteres
    },
    
    # Exemplo: L√¢mpada Yeelight (usa a classe Yeelight)
    "luz da cabeceira": {
        "ip": "10.0.0.Y",
        "token": "SEU_TOKEN_32_CHARS_LUZ"
    }
}
## 3. Execu√ß√£o e Controlo do Sistema Phantasma

O projeto Phantasma √© executado como um servi√ßo Python. O controlo dos dispositivos √© acionado atrav√©s de comandos de linha de comandos ou, tipicamente, por uma interface de voz/mensagem externa que interage com os *skills*.

### A. Estrutura de Execu√ß√£o

Recomenda-se a utiliza√ß√£o de um ambiente virtual Python (venv) para isolar as depend√™ncias e iniciar o servi√ßo principal (`phantasma_core.py`).

1. **Ativar o Ambiente Virtual:**

source venv/bin/activate

### B. Comandos de Controlo de Dispositivos (Intera√ß√£o Direta)

Embora o Phantasma seja concebido para ser ativado por voz ou *scripts* externos, pode testar o controlo de dispositivos diretamente atrav√©s do *core* se este expuser uma API ou *endpoint*. Para a filosofia *local-first*, o controlo baseia-se na identifica√ß√£o do dispositivo configurado em `config.py`.

* **Exemplo de comando Tuya (Exaustor):** O core envia um comando para ligar/desligar o **DPS 1**.
* **Exemplo de comando Miio (Robot):** O core invoca o m√©todo `start_clean` da classe `ViomiVacuum`.

Este *core* (e a sua arquitetura *skill*) √© o motor que traduz o comando de utilizador (ex: "Liga exaustor 1") nas chamadas de controlo local `tinytuya` ou `python-miio`.

---

## 4. Resolu√ß√£o de Problemas Comuns (Troubleshooting) üõ†Ô∏è

* **Falha de Liga√ß√£o (Tuya/Miio):** Quase sempre devido a uma falha na **Reserva de DHCP** (o IP do dispositivo mudou) ou a um **Token/Chave Local** incorreto. Verifique a tabela de DHCP do seu *router* e volte a extrair as chaves se necess√°rio.
* **Controlo N√£o Funciona:** Verifique se as depend√™ncias (`tinytuya`, `python-miio`) est√£o instaladas no ambiente virtual ativo e se o `phantasma_core.py` est√° a ser executado.

## üé§ Hotword (openWakeWord)

O Phantasma migrou do `pvporcupine` para o **openWakeWord** para garantir uma opera√ß√£o **100% livre, offline e perp√©tua**, eliminando a depend√™ncia de chaves de API externas ou licen√ßas que expiram.

### Porqu√™ openWakeWord?

* **Zero Depend√™ncias de Cloud:** N√£o requer registo em servi√ßos de terceiros (como a Picovoice) nem chaves de acesso (`ACCESS_KEY`).
* **Privacidade Total:** Todo o processamento de √°udio √© feito localmente no CPU.
* **Modelos Gratuitos:** Inclui v√°rios modelos pr√©-treinados de alta qualidade prontos a usar.

### Modelos Dispon√≠veis

O sistema vem configurado para carregar automaticamente os modelos inclu√≠dos na biblioteca. Podes ativar o assistente dizendo qualquer uma das seguintes palavras:

* **"Hey Jarvis"** (Padr√£o recomendado)
* **"Alexa"**
* **"Hey Mycroft"**
* **"Hey Rhasspy"**

### Configura√ß√£o

A dete√ß√£o √© gerida no ficheiro `assistant.py`. Atualmente, o sistema carrega todos os modelos pr√©-treinados dispon√≠veis para garantir a m√°xima flexibilidade.

Para treinar uma *hotword* personalizada (ex: "Ei Fantasma"), √© necess√°rio treinar um novo modelo `.onnx` (o openWakeWord n√£o √© compat√≠vel com os ficheiros `.ppn` antigos do Porcupine).


### Notas finais:
O c√≥digo deste modelo e at√© idealiza√ß√£o do projeto, e at√© mesmo este readme √© fortemente gerado pelo Google Gemini.
O modelo para a hotword 'hey fantasma' foi treinada com recurso ao Google Colab.
Como equipamento, estou a usar um HP Mini G4, com 16GB de RAM e um Jabra SPEAK 410 como dispositivo de audio.

## Licen√ßa

O c√≥digo-fonte deste projeto (os ficheiros `.py`, `.sh`, etc.) √© licenciado sob a **Licen√ßa MIT**, como detalhado no ficheiro `LICENSE`.

Este projeto depende de *software* de terceiros com as suas pr√≥prias licen√ßas, incluindo:

* **Ollama (MIT)**
* **OpenAI Whisper (MIT)**
